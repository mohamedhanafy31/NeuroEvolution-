{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eda2190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9741828\n",
      "Accuracy: 0.21978021978021978\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "#!pip install deap\n",
    "import numpy as np\n",
    "import random\n",
    "#from deap import base\n",
    "#from deap import creator\n",
    "#from deap import tools\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Get the features and labels\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "print(data.feature_names)\n",
    "# breast_cancer dataset\n",
    "\n",
    "num_categories = len(np.unique(y))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "input_shape = (x_train.shape[1],)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=input_shape),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(num_categories, activation='softmax')\n",
    "    ])\n",
    "\n",
    "# Feedforwarding the weights\n",
    "predictions = model.predict(x_train, verbose = 0)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate the loss using categorical crossentropy\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_train_one_hot, predictions).numpy()\n",
    "\n",
    "print(\"Loss:\", np.mean(loss))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Get the weights of each layer\n",
    "target_matrix = model.get_weights()\n",
    "#print(target_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ce1a396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "DIMENSIONS = 2\n",
    "BOUND_LOW, BOUND_UP = -2, 2\n",
    "\n",
    "\n",
    "\n",
    "durations = {}\n",
    "# Function to generate a random neural network with given layer configurations\n",
    "def generate_random_network(input_shape, num_categories):\n",
    "    input_shape = (x_train.shape[1],)\n",
    "\n",
    "    # Define the model\n",
    "    model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=input_shape),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(num_categories, activation='softmax')\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "def initialize_population(POPULATION_SIZE, input_shape, num_categories):\n",
    "    \"\"\"\n",
    "    Function to initialize the population of individuals (neural network weights).\n",
    "    \"\"\"\n",
    "    population = []\n",
    "\n",
    "    # Generate random weights for each individual in the population\n",
    "    for _ in range(POPULATION_SIZE):\n",
    "        # Generate a random neural network\n",
    "        model = generate_random_network(input_shape, num_categories)\n",
    "\n",
    "        # Get the weights of each layer\n",
    "        individual_weights = model.get_weights()\n",
    "        population.append(individual_weights)\n",
    "\n",
    "        # Randomly initialize the weights\n",
    "        for inv in population:\n",
    "            for arr in range(len(inv)):\n",
    "                if arr % 2 == 1:\n",
    "                    for i in range(len(inv[arr])):\n",
    "                        inv[arr][i] = random.uniform(-2, 2)  # Use np.random.uniform for continuous values\n",
    "\n",
    "    return population\n",
    "\n",
    "def mutate(i, population, F, model, x_train, y_train_one_hot):\n",
    "    \"\"\"\n",
    "    Function to mutate an individual in the population.\n",
    "    \"\"\"\n",
    "    mutated_matrix = []\n",
    "    vectors_indexes = []\n",
    "    vectors_indexes.append(i)\n",
    "    # print(i)\n",
    "\n",
    "    for _ in range(3):\n",
    "        while len(vectors_indexes) < 4:\n",
    "            random_index = random.randint(0, len(population) - 1)\n",
    "            while random_index not in vectors_indexes:\n",
    "                vectors_indexes.append(random_index)\n",
    "\n",
    "    Target_matrix = population[vectors_indexes[0]]\n",
    "\n",
    "    for j in range(len(Target_matrix)):\n",
    "        mutation_value = population[vectors_indexes[3]][j] + F * (population[vectors_indexes[1]][j] - population[vectors_indexes[2]][j])\n",
    "        mutated_matrix.append(mutation_value)\n",
    "    clip_matrix = [np.clip(item, BOUND_LOW, BOUND_UP) if isinstance(item, np.ndarray) else np.clip(item, BOUND_LOW, BOUND_UP) for item in mutated_matrix]\n",
    "\n",
    "    return clip_matrix\n",
    "\n",
    "def crossover(mutated_matrix, Target_matrix, C, model, x_train, y_train_one_hot):\n",
    "    \"\"\"\n",
    "    Function to perform crossover between mutated and trail matrices.\n",
    "    \"\"\"\n",
    "    trail_matrix = mutated_matrix\n",
    "\n",
    "    for arr in range(len(Target_matrix)):\n",
    "        for elm in range(len(Target_matrix[arr])):\n",
    "            random_num = np.random.rand()  # Generate a single random number\n",
    "            if random_num < C:\n",
    "                trail_matrix[arr][elm] = mutated_matrix[arr][elm]\n",
    "            else:\n",
    "                trail_matrix[arr][elm] = Target_matrix[arr][elm]\n",
    "\n",
    "    return trail_matrix\n",
    "\n",
    "def select_best(target_matrix, trail_matrix, model, x_train, y_train_one_hot):\n",
    "    \"\"\"\n",
    "    Function to select the best between the target and trail matrices.\n",
    "    \"\"\"\n",
    "    model.set_weights(target_matrix)\n",
    "    target_predictions = model.predict(x_train, verbose=0)\n",
    "    loss_target = tf.keras.losses.categorical_crossentropy(y_train_one_hot, target_predictions).numpy()\n",
    "    target_predicted_labels = np.argmax(target_predictions, axis=1)\n",
    "\n",
    "    model.set_weights(trail_matrix)\n",
    "    trail_predictions = model.predict(x_train, verbose=0)\n",
    "    loss_trail = tf.keras.losses.categorical_crossentropy(y_train_one_hot, trail_predictions).numpy()\n",
    "    trail_predicted_labels = np.argmax(trail_predictions, axis=1)\n",
    "\n",
    "    accuracy_target = accuracy_score(y_train, target_predicted_labels)\n",
    "    accuracy_trail = accuracy_score(y_train, trail_predicted_labels)\n",
    "\n",
    "    return target_matrix if np.mean(loss_target) < np.mean(loss_trail) else trail_matrix\n",
    "\n",
    "def calculate_loss(individual, x_train, y_train_one_hot):\n",
    "    \"\"\"\n",
    "    Function to calculate loss and accuracy for an individual.\n",
    "    \"\"\"\n",
    "    # Set weights to the model\n",
    "    model.set_weights(individual)\n",
    "\n",
    "    # Predict using the model\n",
    "    predictions = model.predict(x_train, verbose=0)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_train_one_hot, predictions).numpy()\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_train, predicted_labels)\n",
    "\n",
    "    return np.mean(loss), accuracy\n",
    "\n",
    "def evolve_population(ps, num_generation, input_shape, num_categories, F, C, x_train, y_train_one_hot):\n",
    "    \"\"\"\n",
    "    Function to evolve the population over a number of generations.\n",
    "    \"\"\"\n",
    "    # Initialize the population\n",
    "    population = initialize_population(ps, input_shape, num_categories)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = generate_random_network(input_shape, num_categories)\n",
    "\n",
    "    best_individual = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    history = {}\n",
    "    durations = datetime.timedelta(0)\n",
    "\n",
    "    for generation in range(1, num_generation + 1):\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        print(f\"\\nGeneration no : {generation}\")\n",
    "\n",
    "        # Initialize new_population_parallel for each generation\n",
    "        new_population_parallel = []\n",
    "\n",
    "        # Your existing code for population mutation and other tasks\n",
    "        # Inside the for loop for population mutation and other tasks\n",
    "        for i in range(0, len(population)):\n",
    "            mutated_matrix = mutate(i, population, F, model, x_train, y_train_one_hot)\n",
    "            trail_matrix = crossover(mutated_matrix, population[i], C, model, x_train, y_train_one_hot)\n",
    "            best_matrix = select_best(population[i], trail_matrix, model, x_train, y_train_one_hot)\n",
    "            new_population_parallel.append(best_matrix)\n",
    "\n",
    "\n",
    "        # Calculate loss and accuracy for each individual in the new population\n",
    "        losses_and_accuracy = np.array([calculate_loss(individual, x_train, y_train_one_hot) for individual in new_population_parallel])\n",
    "        # Unpack the tuple correctly\n",
    "        losses = [loss for loss, _ in losses_and_accuracy]\n",
    "\n",
    "\n",
    "        # Find the individual with the lowest loss\n",
    "        if losses:\n",
    "            lowest_loss = np.min(losses)\n",
    "            accuracy = losses_and_accuracy[(losses_and_accuracy == np.min(losses)).any(axis=1)][0][1]\n",
    "            idx = np.where((losses_and_accuracy == np.min(losses_and_accuracy[:, 0])))\n",
    "            print(f\"Lowest loss in generation {generation}: {lowest_loss} and Accuracy : {accuracy}\")\n",
    "\n",
    "        population = new_population_parallel\n",
    "        history[generation] = [int(idx[0][0]),lowest_loss , accuracy]\n",
    "        pop_loss = []\n",
    "        pop_accuracy = []\n",
    "        best_ind = new_population_parallel[int(idx[0][0])]\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "\n",
    "        duration = end_time - start_time\n",
    "        print(f\"Time : {duration}\")\n",
    "        durations +=  duration\n",
    "\n",
    "        # Terminate the algorithm if the best loss is less than 0.15 and accuracy is greater than 0.9\n",
    "        if lowest_loss < 0.15 and accuracy > 0.9:\n",
    "            print(\"Terminating algorithm because best loss is less than 0.15 and accuracy is greater than 0.9\")\n",
    "            break\n",
    "\n",
    "    print(f\"Total generations run Time : {durations}\")\n",
    "    return history, durations, best_ind, population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8645f4eb",
   "metadata": {},
   "source": [
    "## load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae34e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import datetime\n",
    "from functools import partial\n",
    "\n",
    "# Function to load saved networks\n",
    "def load_networks(file_path):\n",
    "    file_path =\"model_train.h5\"\n",
    "    # Load the networks and return them\n",
    "    return np.load(file_path, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cc7df1",
   "metadata": {},
   "source": [
    "## GUI Code \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ef680",
   "metadata": {},
   "source": [
    "## Add Prediction option to the GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8168240",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation no : 1\n",
      "Lowest loss in generation 1: 0.5137633085250854 and Accuracy : 0.7164835164835165\n",
      "Time : 0:00:02.671061\n",
      "\n",
      "Generation no : 2\n",
      "Lowest loss in generation 2: 0.5137633085250854 and Accuracy : 0.7164835164835165\n",
      "Time : 0:00:03.079945\n",
      "\n",
      "Generation no : 3\n",
      "Lowest loss in generation 3: 0.3658366799354553 and Accuracy : 0.8505494505494505\n",
      "Time : 0:00:02.691535\n",
      "\n",
      "Generation no : 4\n",
      "Lowest loss in generation 4: 0.3658366799354553 and Accuracy : 0.8505494505494505\n",
      "Time : 0:00:03.061173\n",
      "\n",
      "Generation no : 5\n",
      "Lowest loss in generation 5: 0.3658366799354553 and Accuracy : 0.8505494505494505\n",
      "Time : 0:00:02.789968\n",
      "\n",
      "Generation no : 6\n",
      "Lowest loss in generation 6: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:03.302334\n",
      "\n",
      "Generation no : 7\n",
      "Lowest loss in generation 7: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:02.966157\n",
      "\n",
      "Generation no : 8\n",
      "Lowest loss in generation 8: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:03.591336\n",
      "\n",
      "Generation no : 9\n",
      "Lowest loss in generation 9: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:02.915205\n",
      "\n",
      "Generation no : 10\n",
      "Lowest loss in generation 10: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:03.093733\n",
      "\n",
      "Generation no : 11\n",
      "Lowest loss in generation 11: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:03.759877\n",
      "\n",
      "Generation no : 12\n",
      "Lowest loss in generation 12: 0.3519609272480011 and Accuracy : 0.8571428571428571\n",
      "Time : 0:00:02.958415\n",
      "Total generations run Time : 0:00:36.880739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation no : 1\n",
      "Lowest loss in generation 1: 0.42291197180747986 and Accuracy : 0.8505494505494505\n",
      "Time : 0:01:03.353514\n",
      "\n",
      "Generation no : 2\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def run_evolution(window, gen_entry, pop_size_entry, f_entry, c_entry, model_path_entry, predict_var, x_train, y_train_one_hot):\n",
    "    num_generations = int(gen_entry.get()) if gen_entry.get() else 0\n",
    "    ps = int(pop_size_entry.get()) if pop_size_entry.get() else 0\n",
    "    F = float(f_entry.get()) if f_entry.get() else 0.0\n",
    "    C = float(c_entry.get()) if c_entry.get() else 0.0\n",
    "    model_path = model_path_entry.get()\n",
    "\n",
    "    model = load_model(model_path)\n",
    "    if predict_var.get() == 1:\n",
    "        predictions = model.predict(x_train, verbose=0)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_train_one_hot, predictions).numpy()\n",
    "        accuracy = accuracy_score(y_train, predicted_labels)\n",
    "        \n",
    "        print(f\"Loss: {np.mean(loss)}, Accuracy: {accuracy}\")\n",
    "    else:\n",
    "        input_shape = (x_train.shape[1],)\n",
    "        num_categories = len(np.unique(y_train))\n",
    "        history_breast_cancer, runTime_breast_cancer, evolv_weights, best_population = evolve_population(ps, num_generations, input_shape, num_categories, F, C, x_train, y_train_one_hot)\n",
    "\n",
    "        labels = list(history_breast_cancer.keys())\n",
    "        losses = [item[1] for item in history_breast_cancer.values()]\n",
    "        accuracies = [item[2] for item in history_breast_cancer.values()]\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(labels, losses, label='Loss')\n",
    "        plt.xlabel(\"Generations\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Evolutionary Algorithm - Loss\")\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(labels, accuracies, label='Accuracy')\n",
    "        plt.xlabel(\"Generations\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Evolutionary Algorithm - Accuracy\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        canvas = FigureCanvasTkAgg(fig, master=window)\n",
    "        canvas.draw()\n",
    "        canvas.get_tk_widget().pack(side=tk.TOP, fill=tk.BOTH, expand=1)\n",
    "\n",
    "def create_gui(x_train, y_train_one_hot):\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Evolutionary Algorithm GUI\")\n",
    "\n",
    "    ttk.Label(window, text=\"Number of Generations:\").pack()\n",
    "    gen_entry = ttk.Entry(window)\n",
    "    gen_entry.pack()\n",
    "\n",
    "    ttk.Label(window, text=\"Population Size:\").pack()\n",
    "    pop_size_entry = ttk.Entry(window)\n",
    "    pop_size_entry.pack()\n",
    "\n",
    "    ttk.Label(window, text=\"F Value:\").pack()\n",
    "    f_entry = ttk.Entry(window)\n",
    "    f_entry.pack()\n",
    "\n",
    "    ttk.Label(window, text=\"C Value:\").pack()\n",
    "    c_entry = ttk.Entry(window)\n",
    "    c_entry.pack()\n",
    "\n",
    "    ttk.Label(window, text=\"Load Model Path:\").pack()\n",
    "    model_path_entry = ttk.Entry(window)\n",
    "    model_path_entry.pack()\n",
    "\n",
    "    load_model_button = ttk.Button(window, text=\"Load Model\", command=lambda: load_model_path(model_path_entry))\n",
    "    load_model_button.pack()\n",
    "\n",
    "    predict_var = tk.IntVar()\n",
    "    predict_var.set(1)\n",
    "    ttk.Checkbutton(window, text=\"Predict\", variable=predict_var, onvalue=1, offvalue=0).pack()\n",
    "    ttk.Checkbutton(window, text=\"Evaluate\", variable=predict_var, onvalue=0, offvalue=1, command=lambda: run_evolution(window, gen_entry, pop_size_entry, f_entry, c_entry, model_path_entry, predict_var, x_train, y_train_one_hot)).pack()\n",
    "\n",
    "    run_button_text = \"Run Evolution\" if predict_var.get() == 1 else \"Evaluate\"\n",
    "    run_button = ttk.Button(window, text=run_button_text, command=lambda: run_evolution(window, gen_entry, pop_size_entry, f_entry, c_entry, model_path_entry, predict_var, x_train, y_train_one_hot))\n",
    "    run_button.pack()\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "def load_model_path(entry):\n",
    "    filename = filedialog.askopenfilename()\n",
    "    entry.delete(0, tk.END)\n",
    "    entry.insert(0, filename)\n",
    "\n",
    "# Assuming x_train and y_train_one_hot are defined earlier in your code\n",
    "# Example: x_train, y_train_one_hot = load_data()\n",
    "\n",
    "# Create and run the GUI\n",
    "create_gui(x_train, y_train_one_hot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409b0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
